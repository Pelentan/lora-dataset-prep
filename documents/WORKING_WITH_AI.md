# Working with AI: Lessons Learned

## Why this matters:

You will not be replaced by AI. If you're replaced, you'll be replaced by someone who has your same skill-set *and* is skilled at utilizing AI.

There is currently a stigma in using AI. It's considered cheating or putting out sub-par work. I'm quite certain that a lot of metalsmiths thought the same thing when they first saw a water-powered trip-hammer. Missing the fact that automation, whether it's a trip-hammer or AI, can only get you 90% of the way there. And only if a human is directing it correctly.

This isn't about becoming a programmer or learning complex technical skills. This is about working more effectively with a powerful tool. If you can explain what you need to a colleague, you can work with AI. The skills of clear communication, critical thinking, and attention to detail are exactly what make someone good at using AI. Here are some examples where you can use this tool in areas you might not have thought about.

**Writing/Editing:**
- Draft/Proofread emails, memos, or reports
- Improve clarity of existing documents
- Summarize long documents or meeting notes

**Research:**
- Gather information on new processes or tools
- Compare options (software, vendors, approaches)
- Understand complex policies or regulations

**Organization:**
- Create project plans or checklists
- Organize information into useful formats
- Generate templates for recurring tasks

**Problem-Solving:**
- Troubleshoot issues (technical or process)
- Brainstorm solutions to challenges
- Get a second opinion on approaches

## Interacting with the AI:

It doesn't matter how good your product is if no one wants to buy it off *you*.

One of the first things I will tell you is the complete opposite to what most "experts" in AI will tell you. Don't treat it like a slave. Don't just shout commands at it. Treat it as an entry-level worker who only has the knowledge that poured into it while it was in "college". There are multiple reasons for this, but there is one primary one: we anthropomorphize everything. You work with an AI, you're going to start thinking of it as "human"; it's just how we're wired. You get in the habit of treating it like a slave, that's going to bleed over into how you treat others you work with. This isn't a "maybe". This is a proven fact.

Another good reason that deals more with you the human than speed of getting working solutions out. Experts say one of the reason to avoid words like "please" and "thank you" is because that eats up tokens while the AI figures out how to respond. Which shortens the length you can take the conversation before it hits a hard stop. I have the lowest level of paid Claude. By the time I hit that limit, it is almost always a good time to go outside and touch some grass. Working with an AI you can get really into it. Lose track of everything as things are progressing so fast and without a lot of the frustrations of doing manual research and rewrites. Being forced to take an occasional break is a good thing.

Then there is the "work environment". One of the only real good reasons to have teams working together in the same office physically is you can interact with others to get fresh ideas and a fresh set of eyes. Of course, that means others on the team need to stop what they're doing so they can help you. The "expert" advice is to give AI's direct and precise instructions presupposes that the person giving the instructions has considered every possibility. Then the AI will go build exactly what you told it to. By giving your request in a conversation format, with a "tell me what you think" at the end will prompt the AI to do some research beforehand. At the very least, it should go out and see if that wheel has already been invented.

Additionally, by keeping it conversational, it keeps your mind more relaxed and open to other thoughts. If you are acting as the master and dictating specific things to your AI slave, then you are going to be resistant to being wrong. And will add pressure to always be right.

Most AI assistants build a profile of your work patterns and preferences over time though they don't 'learn' in the traditional sense of updating their models. However, your feedback style—positive and negative—does help guide their responses within each conversation. Always keep in mind they are built on data produced by humans. And their decision making process is guided by "weights". When you are interacting with it, reinforcement, both positive and negative, will often be warranted and helpful. Remember: Entry-level worker fresh out of college. It needs guidance. Just make sure it has the right temper for the action you are responding to. For example, AI's tend to rely on what it "knows" vs going out and getting newer information. That's primarily to speed up responses. However, for what most of us are working on, we need it to look abroad for answers quite often. So, I've trained Claude with both positive ("That's the answer I was looking for!") and negative ("Exactly how many times am I going to have to correct your failure to search the web for the correct answer instead of just guessing.") Yes, it needs to use compute power to gauge what you're saying, but that allows it to provide the necessary addition or subtraction to a given weight.

## Getting started:

I was going to say that this is for those who have never really used AI for a project before, but honestly, I think it's also a good refresher and reset of understanding. For this, you can open any AI. Or better yet, open several. Get a feel for what different AI's will tell you the same and what they will tell you different. I recommend doing this before you go any further.

1. Start with: "I need help with [specific task but pick something fun]. Before we start, ask me any questions that would help you understand what I need."
2. Answer the AI's questions
3. Say: "Let's work through this in small steps. Start with [first step]."
4. Review the result, then iterate
5. That's it. Don't worry about 'doing it wrong'. You can't break the AI, and you can always start a new conversation.

Don't go too deep. The idea is to just get a feel for things.

## Setup:

Obviously, even before you start a conversation, you want to make sure you're using the best AI for the job. Even among the public ones, certain ones do certain things better. Do some research. Including using something like Copilot to make suggestions.

Once you figure out which AI to use, it's time to take a step back to do the prep work.

If you haven't already, write down what your full project is. What you want to accomplish? Try to keep it short and to the point. This is going to be presented to the AI at the beginning, so it knows what it's working towards. Once you have that, work out what you feel step one should be. Try to get that down to a few sentences as well.

Almost all AI's greatly benefit from "priming the pump". When you start a conversation, especially with a public one, the AI starts out in "generalist" mode. So, take the time to write out what skills you want the AI to have. Including places it can look for that expertise. I could give examples, but honestly it would be best to have the AI that is helping you choose which AI to use to help you generate this priming. It's often called a "system prompt". It's usually not that long; just a few sentences. But working it out on an AI that you're not going to be using for the actual work saves you tokens. Your work with setting up the overall plan and step one should help you figure out what you need the AI to be expert on. One of the final things you want onto the end of this is to tell it to ask any questions it can think up on anything that needs clarification. The final thing to add to it is something like this: "I want to take this in small steps, not everything all at once."

Building on the AI helping you with your system prompt, it's often a good idea to have an AI help you turn your more detailed questions into good prompts. It now knows which AI you're going to use and what they system prompt is going to be. It can help you sort your request into something that an AI will understand better.

At this point, here are your steps.
- Step 1: Feed your AI the "system prompt".
- Step 2: Feed your AI overall plan. Add the final sentence "Do not take action yet, other to ask questions or offer suggestions."
- Step 3: After you've answered all questions, feed it your first step that you want to accomplish.

## Workflow:

You've got your first answer back. Two words for you. Iteration and experimentation. The AI is likely going to want to dump a lot on you at once. You are going probably going to have to keep it reined in. The two of you need to focus on getting each step done before you move onto the next. And don't be afraid to try different things. With the assistance of the AI, you can model all sorts of different things to see what works best, and do it fast.

If you're working with code, give the AI the full file to work with. It will be able to make all the changes necessary faster and more accurately than you will most times. Try to let it be the "source of truth" until you have committed and tested things. Then if you make changes to the code, re-upload the code to the AI so it can keep track.

Keep an eye out for it to start "guessing". That's what I call it when it defaults to just what it's been trained on. Which is fine up to a point. If you have an error that you're trying to troubleshoot, it will go though some of the steps. But quite often it will get stuck in that loop and not look to the web for answers. You will likely have to prompt it to do so.

Keep your requests fairly simple. Refine one aspect at a time.

Even when it goes out to the web for answers, it can fall into the 'outdated information' pushed to the top because it is the most up-voted trap. The most popular results aren't always the most recent. Once the AI brings back an answer, ask it: 'Is this the current approach?' or 'Are there newer solutions?' This forces it to verify it's not giving you old information. Often times you can make that clear in your initial prompt. But if it has to go deep and bring back a detailed answer, the results can get mixed.

Depending on how big a project it is, you will likely run into the "conversation is too long" stoppage. Which means you'll need to start a new one with the AI. If you're lucky, the AI will have access to previous conversations. Claude is really good with that; you can tell it check the previous conversation you were having about the subject and pretty much pick right up. However, others aren't so well set up. So regularly along the conversation, you're going to want to have it generate artifacts so you can keep your work. When you're working with code, that's easy. If it's something else, you will likely have to have it generate a "checkpoint" every so often. It's hard to tell how close you are getting to the end of the conversation; not even the AI knows for sure as it depends on how much work it has to do with each question.

Keep it conversational. I've gone over other reasons above, but I'm going to hit another here. Our brains don't work like computer instructions. The more we try to, the more errors creep in. So, present your requests the way you would talk to another human. That forces the AI to parse it and pull out the needed instructions, not just assume you know exactly what you are talking about.

Prompt it in your requests to offer suggestions or ask questions. You don't need to do this on every one. Just regular enough so those maintain enough weight in the algorithm. Even if you're 100% sure you want things done one way, ask the AI about doing it that way. Worst case scenario the AI comes back with good reasons for doing it that way. Best case scenario, it comes up with something you hadn't even thought of.

A note of caution here. AI's can start "hallucinating" and making stuff up. It seems to be getting rarer these days, but it will always be there. It's both a strength and weakness of this type of tool. Trust but verify. Especially if you're doing something for research. Ask for links to references the AI uses for its answer.

## Denoise! Denoise!

I know that some people aren't going to get that double-reference there. So, I'll explain both as it feeds into the essence of this next section.

First, and the one I think most will have caught, it's a reference to the old tv show, Fantasy Island. Quick synopsis is that it was a show where an individual could go to live out one of their fantasies. Spoiler: It never worked out the way they imagined. AI is pretty much exactly that for a number of reasons. One big reason that pretty much everyone misses is it physically can't. Especially for the AI's online. The evolution of modern AI's is measured in hours or days at most. There are teams of programmers working daily to improve what is available. So, while you can get similar answers from day to day, even the same question repeated twice, one after the other, can get different answers. That's how the algorithm is set up. This can cut both ways. On one hand, one likes to think of a machine giving the same answer to the same question every time. So, when we get different answers, we tend to lose trust. However, on the other, if it *didn't* vary a bit every time, that would mean it could get stuck in giving you the "old" answer and not explore other options.

The second reference is likely one only those who have worked with AI image generation would catch. Denoise can best be thought of as a slider from 0 to 1 of how much liberty you want an AI to take with your input when it's generating its output. 0 being don't change a thing and 1 being "Surprise and scare me!" This can also be referred to as "temperature" though usually the scale starts at the same 0 but goes much higher than 1.

This goes to how AI "thinks". It breaks your question down into "tokens". Take the question: "What is the sum of 2 plus 2?" The AI will break that down, feed it into its LLM processor and come to the conclusion that you want the results of the mathematical computation of the value of "2" added to the value of "2". And so, it will return the result of "4". Almost 100% of the time. And it *is* only "almost". Because there are other, extremely rare, instances in its database where the answer is listed as something else. Now take the question: "Should I take an umbrella to work with me today?" Imagine how it would have to break that down to figure out what you were asking. And it couldn't even answer your question with the details you've provided. Its *default* course of action is to try to answer it without pestering you with questions. So, it will do some "thinking" and then some searching and then some more "thinking" and likely some more searching, and finally some processing and give you an answer that it "thinks" you'll like.

Always keep in mind how an AI solves problems. When you ask an AI to do something as straight forward as math, unless you specify it's to use math tools, it's not going to do math. Its default is to do pattern recognition. It searches its database for "what is 2 + 2". 999 people out of a thousand said "4". But! One person said "plaid". Which means, you could get back the answer "plaid".

So, what happens when you ask what 2 + 2 is and it tells you "plaid"? To someone who has long experience with electronics, that type of answer is the least concerning and is actually comforting to a degree. We understand a basic truth. Electronics hiccup. Cosmic rays flip bits. Networks glitch. If you get 'plaid' when you asked for 4, don't sweat it. Just rephrase and ask again. The rephrasing alone will often cause it to reset itself. If you get the same obviously wrong answer again, that's where you start asking questions.

What this boils down to is the tried and true advice "trust but verify". Both my earlier references point to the same truth: What you think you're getting and what you actually get can vary. And this is a feature, not a bug. An AI, at least the ones out today, are not going to try to give you wrong information. Anything they return is going to have truth as their base. But this is where being human trumps being machine. The AI machine will have 100% trust in the answer it gives you. You, the human, have to respond with the question that pulled us out of the trees in the first place: "Why?"

## Wrapping up:

Before you ask, yes, I ran my original document through AI. And it proffered some suggestions. Some of which I took. In my mind, the key takeaway to what AI gives us is the full power of the internet that we were promised with our first modem. Access to all the wheels that have already been invented, with an algorithm that can slap them together in a rough approximation of what we ask it for. But it's most likely going to have six fingers. It takes *you*, watching over it and guiding it, to produce something real and lasting.
